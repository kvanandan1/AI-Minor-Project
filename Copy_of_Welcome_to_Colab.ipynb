{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# AI Personalized Learning - Dataset Driven\n",
        "# ============================================\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load Dataset\n",
        "# -------------------------------\n",
        "csv_url = \"https://huggingface.co/datasets/merve/student_scores/raw/main/dataset.csv\"\n",
        "df = pd.read_csv(csv_url)\n",
        "\n",
        "# Rename columns (remove spaces for safety)\n",
        "df = df.rename(columns={\n",
        "    \"math score\": \"math_score\",\n",
        "    \"reading score\": \"reading_score\",\n",
        "    \"writing score\": \"writing_score\"\n",
        "})\n",
        "\n",
        "# Add student_id (unique identifier)\n",
        "df[\"student_id\"] = range(1, len(df) + 1)\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Feature Engineering\n",
        "# -------------------------------\n",
        "df[\"average_score\"] = (df[\"math_score\"] + df[\"reading_score\"] + df[\"writing_score\"]) / 3\n",
        "\n",
        "# Subject strength compared to average\n",
        "df[\"math_strength\"] = df[\"math_score\"] - df[\"average_score\"]\n",
        "df[\"reading_strength\"] = df[\"reading_score\"] - df[\"average_score\"]\n",
        "df[\"writing_strength\"] = df[\"writing_score\"] - df[\"average_score\"]\n",
        "\n",
        "# Performance bands\n",
        "def categorize(score):\n",
        "    if score < 60:\n",
        "        return \"Low\"\n",
        "    elif score < 80:\n",
        "        return \"Medium\"\n",
        "    else:\n",
        "        return \"High\"\n",
        "\n",
        "df[\"math_band\"] = df[\"math_score\"].apply(categorize)\n",
        "df[\"reading_band\"] = df[\"reading_score\"].apply(categorize)\n",
        "df[\"writing_band\"] = df[\"writing_score\"].apply(categorize)\n",
        "\n",
        "# Weighted score\n",
        "df[\"weighted_score\"] = (\n",
        "    0.4*df[\"math_score\"] + 0.3*df[\"reading_score\"] + 0.3*df[\"writing_score\"]\n",
        ")\n",
        "\n",
        "# Skill gaps\n",
        "df[\"math_vs_reading_gap\"] = abs(df[\"math_score\"] - df[\"reading_score\"])\n",
        "df[\"math_vs_writing_gap\"] = abs(df[\"math_score\"] - df[\"writing_score\"])\n",
        "df[\"reading_vs_writing_gap\"] = abs(df[\"reading_score\"] - df[\"writing_score\"])\n",
        "\n",
        "# Weak subject flags\n",
        "df[\"is_math_weak\"] = (df[\"math_score\"] < 60).astype(int)\n",
        "df[\"is_reading_weak\"] = (df[\"reading_score\"] < 60).astype(int)\n",
        "df[\"is_writing_weak\"] = (df[\"writing_score\"] < 60).astype(int)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Train/Test Split\n",
        "# -------------------------------\n",
        "dataset = Dataset.from_pandas(df, preserve_index=False)\n",
        "dataset_dict = dataset.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "train_df = dataset_dict['train'].to_pandas()\n",
        "test_df = dataset_dict['test'].to_pandas()\n",
        "\n",
        "features = [\n",
        "    \"math_score\", \"reading_score\", \"writing_score\",\n",
        "    \"math_strength\", \"reading_strength\", \"writing_strength\",\n",
        "    \"weighted_score\",\n",
        "    \"math_vs_reading_gap\", \"math_vs_writing_gap\", \"reading_vs_writing_gap\",\n",
        "    \"is_math_weak\", \"is_reading_weak\", \"is_writing_weak\"\n",
        "]\n",
        "\n",
        "X_train, y_train = train_df[features], train_df[\"average_score\"]\n",
        "X_test, y_test = test_df[features], test_df[\"average_score\"]\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Train Model\n",
        "# -------------------------------\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"âœ… Model trained. MAE on test set: {mae:.2f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Personalized Feedback Function\n",
        "# -------------------------------\n",
        "def generate_feedback_by_id(student_id: int):\n",
        "    student_row = df[df[\"student_id\"] == student_id].iloc[0]\n",
        "\n",
        "    # Prepare features for prediction\n",
        "    student = pd.DataFrame([student_row[features].to_dict()])\n",
        "    predicted_score = model.predict(student)[0]\n",
        "\n",
        "    # Weakness detection\n",
        "    weaknesses = []\n",
        "    if student_row[\"is_math_weak\"]:\n",
        "        weaknesses.append(\"Math\")\n",
        "    if student_row[\"is_reading_weak\"]:\n",
        "        weaknesses.append(\"Reading\")\n",
        "    if student_row[\"is_writing_weak\"]:\n",
        "        weaknesses.append(\"Writing\")\n",
        "\n",
        "    feedback = f\"Needs improvement in {', '.join(weaknesses)}.\" if weaknesses else \"Strong performance across all subjects.\"\n",
        "\n",
        "    # Report\n",
        "    report = (\n",
        "        f\"Student ID: {student_id}\\n\"\n",
        "        f\"Predicted Average Score: {predicted_score:.2f}\\n\"\n",
        "        f\"Performance Bands -> Math: {student_row['math_band']}, \"\n",
        "        f\"Reading: {student_row['reading_band']}, \"\n",
        "        f\"Writing: {student_row['writing_band']}\\n\"\n",
        "        f\"Feedback: {feedback}\"\n",
        "    )\n",
        "    return report\n",
        "\n",
        "def generate_feedback_for_multiple(student_ids: list):\n",
        "    reports = []\n",
        "    for sid in student_ids:\n",
        "        reports.append(generate_feedback_by_id(sid))\n",
        "    return \"\\n\\n\".join(reports)\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Example Usage\n",
        "# -------------------------------\n",
        "print(\"\\nðŸŽ“ Example: Single Student Report\\n\")\n",
        "print(generate_feedback_by_id(10))   # Student with ID 10\n",
        "\n",
        "print(\"\\nðŸŽ“ Example: Multiple Student Reports\\n\")\n",
        "print(generate_feedback_for_multiple([5, 15, 25]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_34c4tWxy3Ok",
        "outputId": "894947cb-45eb-41e4-9ebf-16f11d2933e7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model trained. MAE on test set: 0.28\n",
            "\n",
            "ðŸŽ“ Example: Single Student Report\n",
            "\n",
            "Student ID: 10\n",
            "Predicted Average Score: 49.29\n",
            "Performance Bands -> Math: Low, Reading: Medium, Writing: Low\n",
            "Feedback: Needs improvement in Math, Writing.\n",
            "\n",
            "ðŸŽ“ Example: Multiple Student Reports\n",
            "\n",
            "Student ID: 5\n",
            "Predicted Average Score: 76.42\n",
            "Performance Bands -> Math: Medium, Reading: Medium, Writing: Medium\n",
            "Feedback: Strong performance across all subjects.\n",
            "\n",
            "Student ID: 15\n",
            "Predicted Average Score: 53.65\n",
            "Performance Bands -> Math: Low, Reading: Low, Writing: Low\n",
            "Feedback: Needs improvement in Math, Reading, Writing.\n",
            "\n",
            "Student ID: 25\n",
            "Predicted Average Score: 75.13\n",
            "Performance Bands -> Math: Medium, Reading: Medium, Writing: High\n",
            "Feedback: Strong performance across all subjects.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}